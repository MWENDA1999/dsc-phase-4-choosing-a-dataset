{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ***PROJECT PLAN SUMMARY***\n",
    "\n",
    "To forecast real estate prices and identify the top 5 best zip codes for investment using the Zillow Research dataset, we'll go through a series of steps involving data preprocessing and analysis. The process will include:\n",
    "\n",
    "- ***Data Loading and Inspection:*** We'll start by loading the dataset and inspecting its structure to understand the type of data it contains, including the number of records, columns, and initial observations about the data quality (missing values, data types, etc.).\n",
    "\n",
    "- ***Converting to Long Format:*** Since the data is in wide format (where each column represents a different time point), we'll reshape it into a long format. In long format, each row represents a single time point for a particular zip code. This is essential for time series analysis and modeling.\n",
    "\n",
    "- ***Data Cleaning:*** This step will involve handling missing values, outliers, and any anomalies in the data. Data cleaning ensures the quality and reliability of the dataset for analysis.\n",
    "\n",
    "- ***Feature Engineering:*** We might need to create additional features that could be important for the analysis. This can include calculating metrics like year-over-year price growth, average prices, etc.\n",
    "\n",
    "- ***Exploratory Data Analysis (EDA):*** We'll conduct EDA to understand trends, patterns, and relationships within the data. This step is crucial for gaining insights and guiding the modeling process.\n",
    "\n",
    "- ***Time Series Forecasting Model:*** We'll select and apply suitable time series forecasting models (like ARIMA, SARIMA, Prophet, etc.) to predict future real estate prices for each zip code.\n",
    "\n",
    "- ***Evaluation and Selection:*** Using forecast results and possibly other economic indicators, we'll evaluate and rank the zip codes based on investment potential. Criteria might include forecasted price appreciation, stability of the market, etc.\n",
    "\n",
    "- ***Reporting:*** Finally, we'll compile our findings and recommendations into a report for the investment firm, highlighting the top 5 zip codes for investment along with the rationale for each selection.\n",
    "\n",
    "\n",
    "------------------------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ***1.BUSINESS UNDERSTANDING***\n",
    "## ***Goal:***\n",
    "\n",
    "- Identify the top 5 zip codes for real estate investment, considering potential return on investment, market stability, and future growth prospects.\n",
    "\n",
    "## ***Key Variables (Model Targets):***\n",
    "- Price Appreciation: Growth in property values over time.\n",
    "- Market Stability: Consistency in price trends, indicating lower risk.\n",
    "- Demand Indicators: Factors influencing the desirability of the area (e.g., demographics, economic growth).\n",
    "- Investment Return Potential: Estimated return based on historical and forecasted data.\n",
    "\n",
    "## ***Data Source Identification:***\n",
    "\n",
    "-Primary Source: Zillow Research dataset, providing historical real estate prices by zip code.\n",
    "\n",
    "## ***Objectives:***\n",
    "#### ***Project Goals:***\n",
    "- Quantitative Analysis: Analyze historical price trends and forecast future growth.\n",
    "\n",
    "### ***Success Metrics:***\n",
    "- Financial Returns: Target a specific return rate or price appreciation percentage.\n",
    "- Risk Assessment: Evaluate and limit the investment risk based on market stability."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "----------------------\n",
    "# ***2.DATA ACQUISATION AND UNDERSTANDING***\n",
    "\n",
    "The Zillow dataset provides detailed real estate data, with each row representing a unique zip code. Here's an overview of the dataset structure:\n",
    "\n",
    "- RegionID: A unique identifier for each region.\n",
    "- RegionName: The zip code for the region.\n",
    "- City: The city where the region is located.\n",
    "- State: The state where the region is located.\n",
    "- Metro: The metropolitan area associated with the region.\n",
    "- CountyName: The name of the county where the region is located.\n",
    "- SizeRank: A ranking of the region based on size.\n",
    "- Monthly Price Data: Starting from April 1996 to April 2018, this dataset includes monthly real estate prices for each zip code.\n",
    "\n",
    "We'll analyze historical price trends at a zip code level, which is crucial for our objective of identifying the top 5 zip codes for real estate investment. The analysis will involve:\n",
    "\n",
    "- Trend Analysis: Evaluating the long-term price trends in each zip code.\n",
    "- Volatility Assessment: Understanding the stability or variability in prices over time.\n",
    "- Comparative Analysis: Comparing zip codes across different regions, cities, or states.\n",
    "- Forecasting: Applying statistical or machine learning models to predict future price trends.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Loading the dataset\n",
    "zillow_data = pd.read_csv('zillow_data.csv')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>RegionID</th>\n",
       "      <th>RegionName</th>\n",
       "      <th>City</th>\n",
       "      <th>State</th>\n",
       "      <th>Metro</th>\n",
       "      <th>CountyName</th>\n",
       "      <th>SizeRank</th>\n",
       "      <th>Date</th>\n",
       "      <th>Price</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>84654</td>\n",
       "      <td>60657</td>\n",
       "      <td>Chicago</td>\n",
       "      <td>IL</td>\n",
       "      <td>Chicago</td>\n",
       "      <td>Cook</td>\n",
       "      <td>1</td>\n",
       "      <td>1996-04-01</td>\n",
       "      <td>334200.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>90668</td>\n",
       "      <td>75070</td>\n",
       "      <td>McKinney</td>\n",
       "      <td>TX</td>\n",
       "      <td>Dallas-Fort Worth</td>\n",
       "      <td>Collin</td>\n",
       "      <td>2</td>\n",
       "      <td>1996-04-01</td>\n",
       "      <td>235700.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>91982</td>\n",
       "      <td>77494</td>\n",
       "      <td>Katy</td>\n",
       "      <td>TX</td>\n",
       "      <td>Houston</td>\n",
       "      <td>Harris</td>\n",
       "      <td>3</td>\n",
       "      <td>1996-04-01</td>\n",
       "      <td>210400.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>84616</td>\n",
       "      <td>60614</td>\n",
       "      <td>Chicago</td>\n",
       "      <td>IL</td>\n",
       "      <td>Chicago</td>\n",
       "      <td>Cook</td>\n",
       "      <td>4</td>\n",
       "      <td>1996-04-01</td>\n",
       "      <td>498100.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>93144</td>\n",
       "      <td>79936</td>\n",
       "      <td>El Paso</td>\n",
       "      <td>TX</td>\n",
       "      <td>El Paso</td>\n",
       "      <td>El Paso</td>\n",
       "      <td>5</td>\n",
       "      <td>1996-04-01</td>\n",
       "      <td>77300.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3901590</th>\n",
       "      <td>58333</td>\n",
       "      <td>1338</td>\n",
       "      <td>Ashfield</td>\n",
       "      <td>MA</td>\n",
       "      <td>Greenfield Town</td>\n",
       "      <td>Franklin</td>\n",
       "      <td>14719</td>\n",
       "      <td>2018-04-01</td>\n",
       "      <td>209300.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3901591</th>\n",
       "      <td>59107</td>\n",
       "      <td>3293</td>\n",
       "      <td>Woodstock</td>\n",
       "      <td>NH</td>\n",
       "      <td>Claremont</td>\n",
       "      <td>Grafton</td>\n",
       "      <td>14720</td>\n",
       "      <td>2018-04-01</td>\n",
       "      <td>225800.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3901592</th>\n",
       "      <td>75672</td>\n",
       "      <td>40404</td>\n",
       "      <td>Berea</td>\n",
       "      <td>KY</td>\n",
       "      <td>Richmond</td>\n",
       "      <td>Madison</td>\n",
       "      <td>14721</td>\n",
       "      <td>2018-04-01</td>\n",
       "      <td>133400.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3901593</th>\n",
       "      <td>93733</td>\n",
       "      <td>81225</td>\n",
       "      <td>Mount Crested Butte</td>\n",
       "      <td>CO</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Gunnison</td>\n",
       "      <td>14722</td>\n",
       "      <td>2018-04-01</td>\n",
       "      <td>664400.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3901594</th>\n",
       "      <td>95851</td>\n",
       "      <td>89155</td>\n",
       "      <td>Mesquite</td>\n",
       "      <td>NV</td>\n",
       "      <td>Las Vegas</td>\n",
       "      <td>Clark</td>\n",
       "      <td>14723</td>\n",
       "      <td>2018-04-01</td>\n",
       "      <td>357200.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3901595 rows × 9 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         RegionID  RegionName                 City State              Metro  \\\n",
       "0           84654       60657              Chicago    IL            Chicago   \n",
       "1           90668       75070             McKinney    TX  Dallas-Fort Worth   \n",
       "2           91982       77494                 Katy    TX            Houston   \n",
       "3           84616       60614              Chicago    IL            Chicago   \n",
       "4           93144       79936              El Paso    TX            El Paso   \n",
       "...           ...         ...                  ...   ...                ...   \n",
       "3901590     58333        1338             Ashfield    MA    Greenfield Town   \n",
       "3901591     59107        3293            Woodstock    NH          Claremont   \n",
       "3901592     75672       40404                Berea    KY           Richmond   \n",
       "3901593     93733       81225  Mount Crested Butte    CO                NaN   \n",
       "3901594     95851       89155             Mesquite    NV          Las Vegas   \n",
       "\n",
       "        CountyName  SizeRank       Date     Price  \n",
       "0             Cook         1 1996-04-01  334200.0  \n",
       "1           Collin         2 1996-04-01  235700.0  \n",
       "2           Harris         3 1996-04-01  210400.0  \n",
       "3             Cook         4 1996-04-01  498100.0  \n",
       "4          El Paso         5 1996-04-01   77300.0  \n",
       "...            ...       ...        ...       ...  \n",
       "3901590   Franklin     14719 2018-04-01  209300.0  \n",
       "3901591    Grafton     14720 2018-04-01  225800.0  \n",
       "3901592    Madison     14721 2018-04-01  133400.0  \n",
       "3901593   Gunnison     14722 2018-04-01  664400.0  \n",
       "3901594      Clark     14723 2018-04-01  357200.0  \n",
       "\n",
       "[3901595 rows x 9 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Reshaping the data to long format\n",
    "zillow_long = pd.melt(zillow_data, id_vars=['RegionID', 'RegionName', 'City', 'State', 'Metro', 'CountyName', 'SizeRank'],\n",
    "                      var_name='Date', value_name='Price')\n",
    "\n",
    "# Convert the 'Date' column to a datetime type\n",
    "zillow_long['Date'] = pd.to_datetime(zillow_long['Date'])\n",
    "\n",
    "# Check the first few rows of the reshaped data and its data types\n",
    "reshaped_data = zillow_long\n",
    "data_types = zillow_long.dtypes\n",
    "missing_values = zillow_long.isnull().sum()\n",
    "\n",
    "reshaped_data \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RegionID               int64\n",
       "RegionName             int64\n",
       "City                  object\n",
       "State                 object\n",
       "Metro                 object\n",
       "CountyName            object\n",
       "SizeRank               int64\n",
       "Date          datetime64[ns]\n",
       "Price                float64\n",
       "dtype: object"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_types"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RegionID           0\n",
       "RegionName         0\n",
       "City               0\n",
       "State              0\n",
       "Metro         276395\n",
       "CountyName         0\n",
       "SizeRank           0\n",
       "Date               0\n",
       "Price         156891\n",
       "dtype: int64"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "missing_values.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here's an overview of the reshaped data:\n",
    "\n",
    "- ***Data Structure:*** Each row now contains the RegionID, RegionName (zip code), City, State, Metro, CountyName, SizeRank, the Date of the record, and the corresponding Price.\n",
    "\n",
    "- ***Data Types:*** The Date column has been converted to a datetime type, which is essential for time series analysis. Other columns are appropriately typed (numerical or object).\n",
    "\n",
    "- ***Missing Values:*** There are missing values in the Metro and Price columns. The missing Metro values may not significantly impact the analysis, as we have other location identifiers like City, State, and CountyName. However, the missing Price values are crucial and need to be addressed.\n",
    "\n",
    "Next steps in data preprocessing:\n",
    "\n",
    "- ***Handling Missing Values in Price:*** We need to decide how to handle these missing values. Options include imputation (if the missingness is random and not extensive), or exclusion of records with missing prices. The choice depends on the extent and nature of the missing data.\n",
    "\n",
    "- ***Exploratory Data Analysis (EDA):*** Before diving into modeling, an exploratory analysis to understand the trends and characteristics of the data is crucial. This includes analyzing price trends over time, price distributions across different regions, and any other relevant factors.\n",
    "\n",
    "- ***Feature Engineering:*** Based on the EDA, we might identify additional features that could be useful for the analysis, such as indicators for economic cycles, seasonality effects, or regional economic indicators.\n",
    "\n",
    "- ***Model Selection and Forecasting:*** Once the data is preprocessed, we can select appropriate time series forecasting models to predict future real estate prices.\n",
    "\n",
    "- ***Evaluation and Selection of Top Zip Codes:*** Using the model's forecasts and possibly other economic indicators, we'll evaluate and rank the zip codes based on their potential for investment."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Given the nature of the Zillow dataset and the objective of forecasting real estate prices to identify the best zip codes for investment, the approach to handling missing values and the decision on whether to format the data for time series analysis first are interconnected. Here's an outline of the approach:\n",
    "\n",
    "1. **Understanding Missing Values in Price Data**:\n",
    "   - **Nature of Missingness**: Determine if the missing values are random or systematic. If the missingness is systematic (e.g., missing for specific time periods or specific regions), this could indicate data collection issues or absence of data for newer markets.\n",
    "   - **Percentage of Missingness**: Assess the proportion of missing data. A high percentage of missing data in certain zip codes might lead to unreliable forecasts for those areas.\n",
    "\n",
    "2. **Approaches to Handle Missing Values**:\n",
    "   - **Imputation**: If the missingness is random and not extensive, imputation techniques can be used. Advanced machine learning techniques like K-Nearest Neighbors (KNN) or time series specific methods (like linear interpolation or seasonal decomposition) can be applied.\n",
    "   - **Exclusion**: If the missingness is extensive or systematic, it might be better to exclude those zip codes from the analysis to avoid introducing bias.\n",
    "\n",
    "3. **Preparing for Time Series Analysis**:\n",
    "   - **Time Series Formatting**: It's essential to ensure that the data is correctly formatted for time series analysis. This includes setting the date as an index and ensuring that the data is sorted chronologically.\n",
    "   - **Handling Missing Dates**: If there are missing dates (time points) in the series, they should be identified. Techniques like forward-filling, backward-filling, or interpolation can be used depending on the nature of the data.\n",
    "\n",
    "4. **Exploratory Data Analysis (EDA)**:\n",
    "   - Before delving into modeling, conducting EDA is crucial to understand the underlying patterns, trends, and anomalies in the data.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "count       19.000000\n",
       "mean      8257.421053\n",
       "std       4138.164023\n",
       "min        336.000000\n",
       "25%       5702.000000\n",
       "50%       9170.000000\n",
       "75%      12432.000000\n",
       "max      12462.000000\n",
       "Name: count, dtype: float64"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Analyzing the extent of missing Price values and their nature\n",
    "missing_price_data = zillow_long[zillow_long['Price'].isna()]\n",
    "\n",
    "# Checking if missing values are random or systematic\n",
    "# 1. Checking the distribution of missing values over time\n",
    "missing_over_time = missing_price_data['Date'].dt.year.value_counts().sort_index()\n",
    "\n",
    "# 2. Checking the distribution of missing values across different zip codes\n",
    "missing_by_zip = missing_price_data['RegionName'].value_counts()\n",
    "\n",
    "missing_over_time_summary = missing_over_time.describe()\n",
    "missing_by_zip_summary = missing_by_zip.describe()\n",
    "\n",
    "missing_over_time_summary\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "count    1039.000000\n",
       "mean      151.001925\n",
       "std        43.712452\n",
       "min        15.000000\n",
       "25%       111.000000\n",
       "50%       167.000000\n",
       "75%       183.000000\n",
       "max       219.000000\n",
       "Name: count, dtype: float64"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "missing_by_zip_summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Date\n",
       "1996     9351\n",
       "1997    12462\n",
       "1998    12432\n",
       "1999    12432\n",
       "2000    12432\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "missing_over_time.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RegionName\n",
       "35759    219\n",
       "62870    219\n",
       "48157    219\n",
       "62215    219\n",
       "19954    219\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "missing_by_zip.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "The analysis of missing values in the `Price` column reveals the following:\n",
    "\n",
    "1. **Missing Values Over Time**:\n",
    "   - The missing values are spread across 19 years (1996-2014).\n",
    "   - There's a high variation in the number of missing values per year, with some years having significantly more missing values than others. This indicates that missingness might be systematic to certain time periods.\n",
    "\n",
    "2. **Missing Values Across Zip Codes**:\n",
    "   - The missing values are spread across 1,039 different zip codes.\n",
    "   - There's also variation in the number of missing values per zip code. Some zip codes have more missing data, indicating that certain areas might have more incomplete records.\n",
    "\n",
    "Given these observations, the approach to handle missing values could be as follows:\n",
    "\n",
    "- **Imputation for Random Missingness**: For zip codes with a relatively low number of missing values, imputation might be a suitable approach. Techniques like linear interpolation or time series specific methods (like seasonal decomposition) can be used, as they can account for the temporal nature of the data.\n",
    "\n",
    "- **Exclusion for Systematic Missingness**: For years or zip codes with a high number of missing values, it might be better to exclude those records. This is especially true for zip codes with missing values across a significant portion of the time series, as imputation in such cases might introduce bias.\n",
    "\n",
    "Before proceeding with imputation or exclusion, it's also essential to format the data correctly for time series analysis:\n",
    "\n",
    "- **Time Series Formatting**: Ensure each time series (each zip code) is in chronological order and set the date as an index. This will facilitate further time series specific processing and analysis.\n",
    "\n",
    "- **Handling Missing Dates**: If there are entire missing dates (time points) in the series, decide on a strategy to handle these, such as forward-filling, backward-filling, or interpolation.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>RegionName</th>\n",
       "      <th>Price</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Date</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1996-04-01</th>\n",
       "      <td>23192.0</td>\n",
       "      <td>251640.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1996-04-01</th>\n",
       "      <td>23015.0</td>\n",
       "      <td>183580.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1996-04-01</th>\n",
       "      <td>23047.0</td>\n",
       "      <td>267760.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1996-05-01</th>\n",
       "      <td>23192.0</td>\n",
       "      <td>251640.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1996-05-01</th>\n",
       "      <td>23015.0</td>\n",
       "      <td>183580.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            RegionName     Price\n",
       "Date                            \n",
       "1996-04-01     23192.0  251640.0\n",
       "1996-04-01     23015.0  183580.0\n",
       "1996-04-01     23047.0  267760.0\n",
       "1996-05-01     23192.0  251640.0\n",
       "1996-05-01     23015.0  183580.0"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.impute import KNNImputer\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# Selecting zip codes with a moderate number of missing values for imputation\n",
    "# Setting a threshold for maximum missing values allowed for a zip code to be considered for imputation\n",
    "max_missing_threshold = 50  \n",
    "\n",
    "# Filtering out zip codes with missing values above the threshold\n",
    "zip_codes_for_imputation = missing_by_zip[missing_by_zip <= max_missing_threshold].index\n",
    "data_for_imputation = zillow_long[zillow_long['RegionName'].isin(zip_codes_for_imputation)]\n",
    "\n",
    "# Preparing data for KNN imputation\n",
    "# Dropping non-numeric columns and setting the date as index\n",
    "data_for_imputation_numeric = data_for_imputation.drop(columns=['RegionID', 'City', 'State', 'Metro', 'CountyName', 'SizeRank'])\n",
    "data_for_imputation_numeric.set_index('Date', inplace=True)\n",
    "\n",
    "# Standardizing the data before imputation (KNN imputer is sensitive to the scale of the data)\n",
    "scaler = StandardScaler()\n",
    "data_scaled = scaler.fit_transform(data_for_imputation_numeric)\n",
    "\n",
    "# Applying KNN imputation\n",
    "knn_imputer = KNNImputer(n_neighbors=5)  # The number of neighbors can be adjusted\n",
    "data_imputed = knn_imputer.fit_transform(data_scaled)\n",
    "\n",
    "# Inversing the scaling to get the original scale of prices back\n",
    "data_imputed_original_scale = scaler.inverse_transform(data_imputed)\n",
    "\n",
    "# Creating a DataFrame from the imputed data\n",
    "imputed_data_df = pd.DataFrame(data_imputed_original_scale, columns=data_for_imputation_numeric.columns, index=data_for_imputation_numeric.index)\n",
    "\n",
    "# Checking the first few rows of the imputed data\n",
    "imputed_data_df.head()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ***Next steps:***\n",
    "\n",
    "- ***Integrating Imputed Data Back:*** The imputed data needs to be integrated back into the main dataset. We'll replace the original missing values in these selected zip codes with the imputed values.\n",
    "\n",
    "- ***Handling Zip Codes with Extensive Missingness:*** For zip codes with a high number of missing values (above the threshold), we'll exclude them from the analysis to avoid introducing bias.\n",
    "\n",
    "- ***Time Series Formatting:***\n",
    "  - Ensure the data for each zip code is in chronological order.\n",
    "  - Handle any missing dates in the time series, if necessary, using techniques like forward-filling, backward-filling, or interpolation.\n",
    "\n",
    "- ***Exploratory Data Analysis (EDA):*** Before modeling, it's essential to perform EDA to understand the patterns and trends in the data, which will inform the choice of forecasting models.\n",
    "\n",
    "- ***Model Selection and Forecasting:*** Select appropriate time series forecasting models for the analysis."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
